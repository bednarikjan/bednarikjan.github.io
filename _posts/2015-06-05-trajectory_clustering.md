---
published: false
---

<div class="post">

<p> In this project I worked on a system capable of tracking a human and detecting human gestures using depth data from Microsoft Kinect sensor placed right above the detection region. Of course, there already exist multiple working SW solutions for human tracking (e.g. Microsoft for Kinect SDK, OpenNI etc.), nevertheless neither of those libraries support human recognition and tracking when the sensor is placed right above the tracked person. Here the real challenge started as we had to design and implement the human recognition, tracking and gesture detection from scratch. </p>

<!--more-->

<div>
  <a href="/img/2015-04-15-hum_gest_rec/installation.png">
  <img class="post" src="/img/2015-04-15-hum_gest_rec/installation.png" alt="The sensor installation and the detection region" width="350" align="middle">
  </a>
</div>

<h2>System overview</h2>

<h2>How it works?</h2>

<h2>Implementation</h2>

<h2>Real world application</h2>

<h2>Authors</h2>
<ul>
<li><a href="mailto:jan.bednarik@hotmail.cz">Jan Bednařík</a></li>
</ul>
<p>I worked on this project as an employee of the Czech Republic based tech company <a href="http://www.rcesystems.cz/">RCE systems.</a></p>

<h2>Project materials</h2>

<table>
  <col width="6%">
  <col width="12%">
  <tr>
    <td><img src="/img/source.png" alt="pdf icon" width="40" height="40" align="middle"></td>
    <td><span style="font-variant: small-caps;">Source code (Python):</span></td>
    <td><a href="http://excel.fit.vutbr.cz/2015/submissions/095/95.pdf">Trajetory clustering</a></td>
  </tr>
</table>

</div>

